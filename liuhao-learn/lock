## synchronized
- 隐式锁，锁的释放和获取都有JVM完成。
- jdk1.6以前，完全基于操作系统mutex lock实现的，所以说在使用时会出现内核态和用户态的切换增加性能消耗，被称为重量级锁。
- synchronized的实现原理：
    1. 不管方法修饰还是代码块修饰最终都会调用monitor相关指令,比如monitorenter和monitorexit，只是说修饰方法的时候会有一个ACK_SYNCHRONIED标识
    2. 线程持有monitor对象，然后再执行方法，在这期间其他线程无法获取到monitor对象，当方法执行完了，就释放monitor对象
    3. 每个对象实例都有个monitor，而monitor伴随着实例生命周期而存在，monitor又是由objectMonitor实现，objectMonitor由C++的objectMonitor.hpp实现，
    ```
    ObjectMonitor() { 
    _header = NULL; _count = 0; //记录个数 
    _waiters = 0, 
    _recursions = 0; 
    _object = NULL;
    _owner = NULL;
    _WaitSet = NULL; //处于wait状态的线程，会被加入到_WaitSet
    _WaitSetLock = 0 ;
    _Responsible = NULL ; 
    _succ = NULL ; 
    _cxq = NULL ; 
    FreeNext = NULL ; 
    _EntryList = NULL ; //处于等待锁block状态的线程，会被加入到该列表 _SpinFreq = 0 ; _SpinClock = 0 ; OwnerIsThread = 0 ;}
    ```
    4. 多个线程同时访问的时候，则先会放入_EntryList和contentionList中，然后竞争对象的monitor，而对象的monitor是通过mutex实现互斥的，失败的又回到list中继续等待。
    5. 调用wait()方法线程则会释放持有的monitor，然后进去waitSet等待唤醒，调用notify或者notifyAll则会回到entryList中竞争对象的monitor。
    ![image](https://static001.geekbang.org/resource/image/f7/08/f78e6979c424cce677add97080811308.jpg)
- synchronized的优化:
    1. jdk1.6对synchronize做出了优化，加入了轻量级和偏向锁的概念，因为其实锁一般不会长时间的竞争，所以在持有monitor之前加入偏向锁和轻量级来避免直接调用操作系统的mutex带来的用户态和内核态的切换性能消耗
    2. 这里来说下1.6对锁的优化:此时对象引入了对象头的概念，由MARK WORD,指向类的指针以及数组长度三分部，而所相关则被放在了mark word![image](https://static001.geekbang.org/resource/image/e1/76/e1a3ef8dfea74e0aa81f69081905f876.jpg)如图所示，其中最重要的标识就是线程id。
    3. 当一个线程尝试着去访问同步块的时候就会查看锁状态，没有锁则会去看是否有线程id，如果有则会通过CAS操作尝试更换线程 ID，如果更换失败，则会撤销偏向锁，等待线程到达安全点发生stop the world,再尝试检测原有线程是否退出，没有的话就升级为轻量级锁，线程在轻量级锁的状态下通过CAS操作来不断尝试获取锁，当到达一定次数后则会升级为重量级锁，进入list尝试去获取monitor。如图：![images](https://static001.geekbang.org/resource/image/d9/a2/d9f1e7fae6996a940e9471c47a455ba2.png)
    4. 但是高并发场景 锁一直处理竞争状态 多余的偏向锁stop the world 和 多CAS尝试获取轻量级锁都会带来性能消耗此时应该关闭偏向锁，所以此时推荐
    ```
    -XX:-UseBiasedLocking //关闭偏向锁（默认打开）
    -XX:-UseSpinning //参数关闭自旋锁优化(默认打开) 
    -XX:PreBlockSpin //参数修改默认的自旋次数。JDK1.7后，去掉此参数，由jvm控制
    ```
    5. JIT编译器还对锁进行了消除和粗化，消除是指判断代码是否会多线程访问，不会则会消除同步块，粗化则是相邻的同步块在允许的条件下合并成一个同步块减少申请锁带来的消耗。
    6. 这里说个题外话，还可以通过减小锁粒度来减小锁的竞争频率来让偏向锁和轻量级锁发挥作用，比如；数据分段，一个锁只负责一段数据来降低频率
    
    
## LOCK
- Lock显示锁 由java底层实现，加入了公平锁的概念，唤醒时随队列先后，显式的获取锁释放锁
```
Lock.lock()//获取锁，如果被锁定则等待
Lock.tryLock()//未被锁定才获取锁
Lock.tryLock(timeout,TimeUnut unut)//最多等待多久

```
- ReentrantLock 重入锁  基础abstractQueuedSynchronized (AQS)实现：AQS内部有一个链表实现的队列（CLH），用于存储所有阻塞线程，还有一个status状态码 来表示锁状态，线程访问锁，先获取它的status状态，如果状态不为0说明有锁，然后再查看线程ID是否是自己，如果不是自己则丢入等待队列CLH，再看自己是不是在CLH首位且CAS尝试获取锁状态，如果不是则休眠等待唤醒。这里说的是最极端的情况，如果在过程中获取到锁，如果是重入还要看重入的次数是否超过最大次数，如果超出则抛异常!具体如图：![image](https://static001.geekbang.org/resource/image/22/33/222196b8c410ff4ffca7131faa19d833.jpg)
- ReenTrantReadWriteLock 读写锁，适用于读多写少的场景，内部提供了readLock和writeLock，读锁是一把共享锁，写锁是独占锁，它也是基于AQS实现的，提供一个status的状态码来标识锁的状态，这里个ReenTrantLoock不一样的是status通过高16位和低16位的方式来分别标识读和写获取锁的状态，提供一个链表实现的队列（CLH）来存储所有阻塞的线程，也会判断重入是否超过最大重入次数。简单描述下读写锁的流程:获取写锁先看status是否为0，不为0则表示有锁，再判断低16位是否为0，不为0则为写锁，反之则为读锁，查看是否是当前线程获取的写锁，如果不是查看是否是公平锁，如果不是丢入CLH等待队列，判断是否是首位且CAS获取锁状态，不是则休眠等待。如图:![image](https://static001.geekbang.org/resource/image/1b/d1/1bba37b281d83cdf0c51095f473001d1.jpg)再强调一下这里的公平锁，公平锁的概念就是在获取锁的时候会去查看等待队列，如果有就会直接进入等待队列，而非公平锁能获取锁则直接获取锁，在有的时候来得早不如来得巧就是这么个道理，因为这样非公平锁的性能比公平锁的5-10倍，公平锁增加了线程的切换次数。
- stampedLock
```
package com.liuhao.thread;

import java.util.concurrent.locks.StampedLock;

public class TestStampedLock {

    private double x,y;
    private StampedLock stampedLock = new StampedLock();

    public double read(){
        //获取乐观锁 如果没有写锁在 则stamp 值不为0 此时共享变量会拷贝到栈中 这里和volatile不一样
        long stamp = stampedLock.tryOptimisticRead();
        //把最新的值记录
        double a=x,b=y;
        //此间没有线程操作过锁 则直接返回值
        if(!stampedLock.validate(stamp)){
            //不然就升级成悲观锁
            stamp = stampedLock.readLock();
            try{
                a = x;
                b = y;

            }finally {
                stampedLock.unlockRead(stamp);
            }


        }

        return Math.sqrt(a*a+b*b);
    }


    public void write(){

    }

}
```
读写锁，不可重入，不可设置条件。也是用AQS原理实现的，不同是获取锁返回了一个stamp票据，根据这个票据可以判断当前线程状态，同时拷贝了一份共享数据回栈，乐观锁虽然每次取的最新的数据但是因为不阻塞不会影响写锁的竞争，就不会ReentrantReadWriteLock读多写少读锁竞争的饥饿问题，这里升级成悲观锁有一点的作用。第一次乐观锁节省了一次CAS操作带来的性能消耗。

## 乐观锁
- 和悲观锁相比没有所谓的竞争、阻塞、饥饿问题，所以也不会带来死锁的问题。乐观锁的实现其核心思想：三个值，需要更新的值，更新预期值，最新值，当更新预期值=最新值时更新的变量才会被设置成最新值，CAS即Compare and Swap这种无锁算法底层是怎么实现的了？在CPU存在总线锁定和缓存锁定，多核操作情况当总线需要操作一个共享变量的时候就会发出一个lock，此时其他处理器就不能操作共享变量，该处理器独享内存中的共享变量，但这样就会导致其他处理器阻塞，从而增加性能开销。于是就提供了新的缓存锁定机制，当一个处理器需要操作一个共享变量时就通知其他处理器放弃该共享资源的操作或者重新读取新的共享资源。<font color = "red">目前最新的处理器都支持缓存锁定机制。</font>
- JDK并发包的atomic同理，在高并发写的情况会出现频繁的失败重试导致CPU开销增大
- JDK1.8 提供了LongAdder这种新的原子类，其用空间换取时间，在高并发的情况分槽记录每个线程的操作后续再做统计，这样导致的问题就是返回的值可能不是最终准确值，因为可能还存在没有统计值的在数组。

## 性能
最终还是放个图：在读多写少、写多读少、都差不多的情况的锁的性能比较.<font color="red">这里补充一点 synchronized 和 reentrantLock 虽然在高并发的情况 性能不如 reentrantReadWriteLock、stampLock、longAdder乐观锁，但是在竞争锁不是那么频繁的访问的时候也有其好处。比如synchronize实现简单、编译器会对其优化合并相邻的同步块减少申请锁的开销</font>，最后上图：![image](https://static001.geekbang.org/resource/image/d5/1e/d5906bf5be6a91cb4ab3e4511da2421e.jpg)
